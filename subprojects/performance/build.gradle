/*
 *  Licensed to the Apache Software Foundation (ASF) under one
 *  or more contributor license agreements.  See the NOTICE file
 *  distributed with this work for additional information
 *  regarding copyright ownership.  The ASF licenses this file
 *  to you under the Apache License, Version 2.0 (the
 *  "License"); you may not use this file except in compliance
 *  with the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing,
 *  software distributed under the License is distributed on an
 *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 *  KIND, either express or implied.  See the License for the
 *  specific language governing permissions and limitations
 *  under the License.
 */
plugins {
    id 'org.apache.groovy-performance'
}

performanceTests {
    versions '2.5.20',
            '3.0.14',
            '4.0.7',
            'current'

    testFiles project.files("src/files") +
            project.files('src/jmh/groovy/org/apache/groovy/bench/Ackermann.groovy') +
            project.files('src/jmh/groovy/org/apache/groovy/bench/Ary.groovy') +
            project.files('src/jmh/groovy/org/apache/groovy/bench/Fibo.groovy')
}

def jmhResultsDir = layout.buildDirectory.dir("results/jmh")

// ============================================================================
// Threshold Parameter Sweep
// ============================================================================

/**
 * Run benchmarks with different optimize threshold values.
 * Helps determine optimal threshold for different workloads.
 */
tasks.register('jmhThresholdSweep') {
    group = 'benchmark'
    description = 'Run benchmarks with varying groovy.indy.optimize.threshold values'

    def thresholds = [0, 10, 100, 1000, 10000, 100000]
    def sweepDir = layout.buildDirectory.dir("results/jmh-threshold-sweep")

    doFirst {
        sweepDir.get().asFile.mkdirs()
    }

    doLast {
        def results = [:]

        thresholds.each { threshold ->
            println ""
            println "=" * 60
            println "Running with groovy.indy.optimize.threshold = ${threshold}"
            println "=" * 60

            def outputFile = sweepDir.get().file("threshold-${threshold}.txt").asFile

            // Run JMH with this threshold
            project.javaexec {
                mainClass = 'org.openjdk.jmh.Main'
                classpath = files(tasks.named('jmhJar'))
                args '-rf', 'text'
                args '-rff', outputFile.absolutePath
                args '-wi', '3'  // Reduced warmup for sweep
                args '-i', '3'   // Reduced iterations for sweep
                args '-f', '1'   // Single fork for sweep

                if (project.hasProperty('benchInclude')) {
                    args '.*' + project.benchInclude + '.*'
                }

                jvmArgs "-Dgroovy.indy.optimize.threshold=${threshold}"
            }

            // Parse results
            if (outputFile.exists()) {
                outputFile.eachLine { line ->
                    def match = line =~ /^(\S+)\s+\S+\s+\d+\s+([\d.]+)/
                    if (match) {
                        def name = match[0][1]
                        def score = match[0][2] as double
                        if (!results[name]) results[name] = [:]
                        results[name][threshold] = score
                    }
                }
            }
        }

        // Generate summary report
        def summaryFile = sweepDir.get().file("threshold-summary.txt").asFile
        summaryFile.withWriter { writer ->
            writer.writeLine "=" * 100
            writer.writeLine "THRESHOLD SWEEP SUMMARY"
            writer.writeLine "Generated: ${new Date()}"
            writer.writeLine "=" * 100
            writer.writeLine ""
            writer.writeLine String.format("%-50s %s", "Benchmark", thresholds.collect { String.format("%10d", it) }.join(""))
            writer.writeLine "-" * 100

            results.keySet().sort().each { name ->
                def scores = thresholds.collect { t ->
                    results[name][t] ? String.format("%10.3f", results[name][t]) : String.format("%10s", "N/A")
                }.join("")
                writer.writeLine String.format("%-50s %s",
                    name.length() > 50 ? "..." + name[-47..-1] : name,
                    scores)
            }

            writer.writeLine ""
            writer.writeLine "Optimal thresholds by benchmark:"
            writer.writeLine "-" * 50
            results.keySet().sort().each { name ->
                def scores = results[name]
                def optimal = scores.min { it.value }?.key
                if (optimal != null) {
                    writer.writeLine String.format("%-50s %d",
                        name.length() > 50 ? "..." + name[-47..-1] : name,
                        optimal)
                }
            }
        }

        println ""
        println "Threshold sweep summary saved to: ${summaryFile}"
        println ""
        println summaryFile.text
    }
}

// ============================================================================
// Profiling Support
// ============================================================================

/**
 * Run JMH with JFR (Java Flight Recorder) profiling enabled.
 */
tasks.register('jmhProfile', JavaExec) {
    dependsOn 'jmhJar'
    group = 'benchmark'
    description = 'Run JMH benchmarks with JFR profiling enabled'

    mainClass = 'org.openjdk.jmh.Main'
    classpath = files(tasks.named('jmhJar'))

    def profileDir = layout.buildDirectory.dir("results/jmh-profile")
    def jfrFile = profileDir.map { it.file("benchmark.jfr") }

    // Reduce iterations for profiling
    args '-wi', '2'
    args '-i', '3'
    args '-f', '1'

    if (project.hasProperty('benchInclude')) {
        args '.*' + project.benchInclude + '.*'
    }

    jvmArgs '-XX:+FlightRecorder'
    jvmArgs "-XX:StartFlightRecording=duration=60s,filename=${jfrFile.get().asFile.absolutePath}"

    doFirst {
        profileDir.get().asFile.mkdirs()
        println "Running JMH with JFR profiling"
        println "JFR output will be saved to: ${jfrFile.get().asFile}"
        println ""
        println "After completion, analyze with:"
        println "  jfr print ${jfrFile.get().asFile}"
        println "  jfr summary ${jfrFile.get().asFile}"
        println "Or open in JDK Mission Control (jmc)"
    }
}

/**
 * Run JMH with GC profiler for memory analysis.
 */
tasks.register('jmhGcProfile', JavaExec) {
    dependsOn 'jmhJar'
    group = 'benchmark'
    description = 'Run JMH benchmarks with GC profiler for memory analysis'

    mainClass = 'org.openjdk.jmh.Main'
    classpath = files(tasks.named('jmhJar'))

    def outputFile = jmhResultsDir.map { it.file("gc-profile-results.txt") }

    args '-rf', 'text'
    args '-rff', outputFile.get().asFile.absolutePath
    args '-prof', 'gc'

    if (project.hasProperty('benchInclude')) {
        args '.*' + project.benchInclude + '.*'
    }

    doFirst {
        println "Running JMH with GC profiler"
        println "Results will be saved to: ${outputFile.get().asFile}"
    }
}

// ============================================================================
// Baseline Management
// ============================================================================

def baselinesDir = file("baselines")

/**
 * Save current benchmark results as a baseline.
 */
tasks.register('jmhSaveBaseline') {
    dependsOn 'jmh'
    group = 'benchmark'
    description = 'Save current JMH results as a baseline for future comparison'

    doLast {
        def baselineName = project.hasProperty('baselineName') ? project.baselineName : "baseline-${new Date().format('yyyyMMdd-HHmmss')}"
        def resultsFile = jmhResultsDir.get().file("results.txt").asFile
        def baselineFile = new File(baselinesDir, "${baselineName}.txt")

        if (!resultsFile.exists()) {
            println "ERROR: No JMH results found. Run jmh first."
            return
        }

        baselinesDir.mkdirs()
        baselineFile.text = resultsFile.text

        println "Baseline saved to: ${baselineFile}"
    }
}

/**
 * Compare current results against a saved baseline.
 */
tasks.register('jmhCompareBaseline') {
    dependsOn 'jmh'
    group = 'benchmark'
    description = 'Compare current JMH results against a saved baseline'

    doLast {
        def baselineName = project.hasProperty('baselineName') ? project.baselineName : null
        def baselineFile = baselineName ? new File(baselinesDir, "${baselineName}.txt") : null

        // Find most recent baseline if not specified
        if (!baselineFile?.exists()) {
            def baselines = baselinesDir.listFiles()?.findAll { it.name.endsWith('.txt') }?.sort { -it.lastModified() }
            baselineFile = baselines?.first()
        }

        if (!baselineFile?.exists()) {
            println "ERROR: No baseline found. Run jmhSaveBaseline first."
            return
        }

        def currentFile = jmhResultsDir.get().file("results.txt").asFile
        if (!currentFile.exists()) {
            println "ERROR: No current results found. Run jmh first."
            return
        }

        def parseResults = { File file ->
            def results = [:]
            file.eachLine { line ->
                def match = line =~ /^(\S+)\s+(\S+)\s+(\d+)\s+([\d.]+)\s*±?\s*([\d.]*)\s*(\S+)/
                if (match) {
                    def name = match[0][1]
                    def score = match[0][4] as double
                    results[name] = score
                }
            }
            results
        }

        def baseline = parseResults(baselineFile)
        def current = parseResults(currentFile)

        println ""
        println "=" * 80
        println "BASELINE COMPARISON"
        println "Baseline: ${baselineFile.name}"
        println "Current:  ${currentFile.name}"
        println "=" * 80
        println ""
        println String.format("%-50s %12s %12s %12s", "Benchmark", "Baseline", "Current", "Change")
        println "-" * 90

        def allBenchmarks = (baseline.keySet() + current.keySet()).unique().sort()
        def regressions = []
        def improvements = []

        allBenchmarks.each { name ->
            def baseScore = baseline[name]
            def currScore = current[name]

            if (baseScore && currScore) {
                def change = ((currScore - baseScore) / baseScore) * 100
                def changeStr = String.format("%+.1f%%", change)

                if (change > 10) {
                    changeStr += " REGRESSION"
                    regressions << [name: name, change: change]
                } else if (change < -10) {
                    changeStr += " IMPROVED"
                    improvements << [name: name, change: change]
                }

                println String.format("%-50s %12.3f %12.3f %12s",
                    name.length() > 50 ? "..." + name[-47..-1] : name,
                    baseScore, currScore, changeStr)
            }
        }

        println ""
        if (regressions) {
            println "REGRESSIONS (>10% slower):"
            regressions.each { println "  - ${it.name}: ${String.format('%+.1f%%', it.change)}" }
        }
        if (improvements) {
            println "IMPROVEMENTS (>10% faster):"
            improvements.each { println "  - ${it.name}: ${String.format('%+.1f%%', it.change)}" }
        }
    }
}

// ============================================================================
// Dynamic Benchmark Grouping (for CI matrix)
// ============================================================================

/**
 * Discover all JMH benchmarks from the fat jar and group them by subpackage
 * into appropriately-sized chunks for parallel CI execution.
 *
 * Outputs build/jmh-groups.json — an array of {group, pattern} objects.
 */
tasks.register('jmhGroups') {
    group = 'benchmark'
    description = 'Discover JMH benchmarks and output groups as JSON for CI matrix'
    dependsOn 'jmhJar'

    def outputFile = layout.buildDirectory.file("jmh-groups.json")
    outputs.file(outputFile)

    doLast {
        // Time estimate: 1 fork × (1 warmup @10s + 1 iteration @10s) + ~5s overhead
        def secondsPerMethod = 25
        def maxSecondsPerJob = 600 // 10-minute target
        def maxPerGroup = (int) (maxSecondsPerJob / secondsPerMethod)

        // List all benchmarks from the fat jar
        def listing = new ByteArrayOutputStream()
        project.javaexec {
            mainClass = 'org.openjdk.jmh.Main'
            classpath = files(tasks.named('jmhJar'))
            args '-l'
            standardOutput = listing
        }

        def benchmarks = listing.toString().readLines()
            .collect { it.trim() }
            .findAll { it.startsWith('org.apache.groovy.') }

        // Group by subpackage: bench.dispatch.* → "dispatch", bench.Foo → "core", plugin.* → "plugin"
        def groups = benchmarks.groupBy { fqcn ->
            def parts = (fqcn - 'org.apache.groovy.').split('\\.')
            parts[0] == 'bench' ? (parts.length >= 4 ? parts[1] : 'core') : parts[0]
        }.sort()

        // Build entries, splitting large groups by class
        def entries = []
        groups.each { name, methods ->
            if (methods.size() <= maxPerGroup) {
                def pattern = name == 'core'
                    ? ".*(" + methods.collect { it.split('\\.')[-2] }.unique().sort().join('|') + ").*"
                    : ".*\\.${name}\\..*"
                entries << [group: name, pattern: pattern, benchmarks: methods.size()]
            } else {
                def byClass = methods.groupBy { it.split('\\.')[-2] }
                def chunk = []
                int chunkMethods = 0
                int chunkNum = 1
                byClass.sort().each { cls, meths ->
                    if (chunkMethods + meths.size() > maxPerGroup && chunk) {
                        entries << [group: "${name}-${chunkNum}", pattern: ".*(" + chunk.join('|') + ").*", benchmarks: chunkMethods]
                        chunk = []
                        chunkMethods = 0
                        chunkNum++
                    }
                    chunk << cls
                    chunkMethods += meths.size()
                }
                if (chunk) {
                    entries << [group: "${name}-${chunkNum}", pattern: ".*(" + chunk.join('|') + ").*", benchmarks: chunkMethods]
                }
            }
        }

        def json = groovy.json.JsonOutput.prettyPrint(groovy.json.JsonOutput.toJson(entries))
        outputFile.get().asFile.text = json
        println json
    }
}
